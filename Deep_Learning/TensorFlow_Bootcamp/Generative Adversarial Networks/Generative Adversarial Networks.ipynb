{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs were first reported in 2014. They have the capability to generate new samples similar to the data they were trained on. For example, creating new faces after being trained on large datasets of faces.\n",
    "\n",
    "We'll build two networks, a generator and a discriminator. The idea is that we are training a generator to produce samples that the discriminator compares against a sample of real data. Eventually, the generator is able to fool the discriminator into passing a generated sample as real.\n",
    "\n",
    "The coding is essentially really simple; the real thing is tuning the hyperparameters and the training time involved.\n",
    "\n",
    "- Discriminator overpowering Generator:\n",
    "\n",
    "If the discriminator classifies all examples as fake, there is no progress. You may want to have discriminator ouput be unscaled instead of sigmoid.\n",
    "\n",
    "- Generator overpowering Discriminator: Mode Collapse\n",
    "\n",
    "The generator discovers some weakness in the discriminator, and the generator ends up producing a similar example regardless of variation in input. You can try adjusting the training rate or changing layers of the discriminator in an attempt to make it better.\n",
    "\n",
    "GANs are so powerful, they are limited by the hardware that you are using.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate numbers based off the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-6f8a0212a6c1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/alvaro/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/alvaro/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alvaro/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alvaro/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alvaro/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[14].reshape(28, 28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(z, reuse=None):\n",
    "    # gen for generator. The goal is to allow to have modular sections of parameters.\n",
    "    with tf.variable_scope('gen', reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z, units=128)\n",
    "        \n",
    "        # leaky relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        \n",
    "        # second layer, same thing\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        \n",
    "        # output\n",
    "        output = tf.layers.dense(hidden2, units=784, activation=tf.nn.tanh)\n",
    "        \n",
    "        return output      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(z, reuse=None):\n",
    "    # dis for discriminator. The goal is to allow to have modular sections of parameters.\n",
    "    with tf.variable_scope('dis', reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z, units=128)\n",
    "        \n",
    "        # leaky relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        \n",
    "        # second layer, same thing\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        \n",
    "        # output\n",
    "        logits = tf.layers.dense(hidden2, units=1) # probability of being real/fake\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Images\n",
    "real_images = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "# Noise\n",
    "z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "# Generator and Discriminator\n",
    "G = generator(z)\n",
    "D_output_real, D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "def loss_function(logits_in, labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_function(D_logits_real, tf.ones_like(D_logits_real)*0.9) # I want all elements to be REAL (times smoothing factor 0.9)\n",
    "\n",
    "D_fake_loss = loss_function(D_logits_fake, tf.zeros_like(D_logits_real))\n",
    "\n",
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = loss_function(D_logits_fake, tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
