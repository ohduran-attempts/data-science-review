{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will cover:\n",
    "    \n",
    "- Explanation of Hadoop, MapReduce, Spark and PySpark\n",
    "- Local versus Distributed Systems\n",
    "- Overview of Hadoop Ecosystem\n",
    "- Detailed overview of Spark\n",
    "- Set-up on AWS\n",
    "- Resources on other Spark options\n",
    "- Notes on PySpark and RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked with data that can fit on a local computer. But what can we do if we have a larger set of data?\n",
    "\n",
    "- Try using a SQL database to move storage onto a hard drive instead of RAM\n",
    "- Or try using a distributed system, that distributes the data to multiple computers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed system means controlling the ouput of several machines from one computer. A distributed process has access to the computational resources across a number of machines connected through a network. After a certain point, it's easier to scale out many lower CPUs, than try to scale up a single one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distributed machines can also scale very easily (just add more machines)\n",
    "- Distributed machines include fault tolerance (if one machine fails, the network can still go on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop is a way to distribute very large files across multiple machines. It uses the Hadoop Distributed File System (HDFS).\n",
    "- Allows a user to work with large datasets.\n",
    "- Duplicates blocks of data for fault tolerance.\n",
    "- Uses MapReduce (allows computation on that data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce is a way of splitting a computation task to a distributed set of files. It consists of a Job Tracker and multiple Task Trackers.\n",
    "\n",
    "The Job Tracker sends code to run on the Task Tracker, and the Task Tracker allocates CPU and memory for the tasks and monitor the tasks on the worker nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is one of the latest technologies being used to handle Big Data. It's an open source project on Apache, first released on 2013. It can be considered a flexible alternative to MapReduce: can use data stored in a variety of formats, such as Cassandra, AWS S3, HDFS, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can perform operations up to 100x faster than MapReduce, by keeping most of the data in memory after each transformation (spilling over to disk if memory is filled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resilient Distributed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDDs are distributed collections of data, fault tolerant, can be partitioned and have the ability to use many data sources. There are two types of RDD operations:\n",
    "\n",
    "- Transformations\n",
    "- Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Actions:\n",
    "\n",
    "- First: Return the first element in the RDD.\n",
    "- Collect: Return all elements of the RDD as an array at the driver program.\n",
    "- Count: Return the number of elements in the RDD.\n",
    "- Take: Return an array with the first n elements of the RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Transformations:\n",
    "\n",
    "- Filter: Applies a function to each element and returns elements that evaluate to True.\n",
    "- Map: Transforms each element and preserves # of elements, very similar to pd.apply(). (Like grabbing the first letter of a list of names)\n",
    "- FlatMap: Transform each element into 0-N elements and changes # of elements. (Like transforming a corpus of text into a list of words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, RDDs will be holding their values in tuples (key, value). This offers better partitioning of data and leads to functionality based on reduction.\n",
    "\n",
    "New Actions (similar to .groupby() )\n",
    "\n",
    "- Reduce: Aggregates RDD elements using a function that returns a single element.\n",
    "- ReduceByKey: Aggregates Pair RDD elements using a function that returns a Pair RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
