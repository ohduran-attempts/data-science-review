{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.76470596, 0.9960785 , 1.        , 0.93725497,\n",
       "        0.1137255 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
       "        0.6392157 , 0.9960785 , 0.9960785 , 0.6862745 , 0.21568629,\n",
       "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.47450984,\n",
       "        0.9960785 , 0.9960785 , 0.5803922 , 0.03137255, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "        0.9294118 , 0.43921572, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16862746, 0.9607844 ,\n",
       "        0.9960785 , 0.9490197 , 0.01568628, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20784315, 0.92549026,\n",
       "        0.9960785 , 0.43921572, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6431373 , 0.9960785 ,\n",
       "        0.9803922 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "        0.97647065, 0.1254902 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.83921576, 0.9960785 ,\n",
       "        0.69803923, 0.        , 0.        , 0.01176471, 0.03529412,\n",
       "        0.03529412, 0.03529412, 0.17254902, 0.909804  , 0.9960785 ,\n",
       "        0.64705884, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.83921576, 0.9960785 ,\n",
       "        0.7254902 , 0.        , 0.21176472, 0.7294118 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9058824 ,\n",
       "        0.16862746, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37647063, 0.9960785 ,\n",
       "        0.9803922 , 0.74509805, 0.98823535, 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.50980395,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.49411768, 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.7803922 , 0.46274513,\n",
       "        0.5686275 , 0.9960785 , 0.9960785 , 0.9960785 , 0.30588236,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10980393, 0.47058827,\n",
       "        0.47058827, 0.47058827, 0.1254902 , 0.01176471, 0.        ,\n",
       "        0.47450984, 0.9960785 , 0.9960785 , 0.76470596, 0.01568628,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43137258, 0.9960785 , 0.9960785 , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.41960788, 0.9960785 , 0.98823535, 0.19215688, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.8235295 , 0.9960785 , 0.7176471 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
       "        0.87843144, 0.9960785 , 0.2784314 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.27058825,\n",
       "        0.9960785 , 0.97647065, 0.20784315, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8470589 ,\n",
       "        0.9960785 , 0.92549026, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.74509805, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.73333335, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.97647065, 0.49411768, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44705886,\n",
       "        0.9333334 , 0.9960785 , 0.48627454, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].reshape(28,28) # the image is 28 by 28 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2eae5447f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are training our model to predict, by giving them the pixel representation of the numbers and the label, what number is written in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Adam Optimizer to get the model right. See [here](https://medium.com/@nishantnikhil/adam-optimizer-notes-ddac4fd7218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_6:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_7:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_8:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input]) # input\n",
    "y = tf.placeholder('float', [None, n_classes]) # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
