{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like perceptrons, CNNs also have their origins in biological research. This research revealed that neurons in the visual cortex had a small local receptive field: some neurons only look at smaller subsections of the complete image, and these subsections can overlap to produce the complete image.\n",
    "\n",
    "Let's break the various aspects of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Recall that Tensors are N-Dimensional arrays that we build up to, from scalars (N=0) to Tensors (N=3). They make it very convenient to feed in sets of images into our model:\n",
    "\n",
    "- Images\n",
    "- Height of Image in Pixels\n",
    "- Width of Image in Pixels\n",
    "- Color Channels (Grayscale, RGB, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN vs CNN\n",
    "\n",
    "A Densed connected layer is connected to every other neuron in the next layer. A convolutional layer uses a different approach: each unit is connected to a smaller number of nearby units in the next layer, based on the locality idea previously discussed.\n",
    "\n",
    "But why bother? Well, MNIST dataset was 28x28, but most images are at least 256x256, leading to too many parameters, unscalable to new images...\n",
    "\n",
    "Also, convolutions have a major advantage for image processing, where pixels nearby to each other are much more correlated for image detection.\n",
    "\n",
    "- Each CNN layer looks at an increasingly larger part of the image.\n",
    "- Having units only connected to nearby units also aids in *invariance*.\n",
    "- CNN also helps with regularization, limiting the search of weights to the size of the convolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and Filters\n",
    "We can treat weights on layers as filters: only some special combination of inputs will activate the neuron, effectively converting some of these inputs into 'catalysts' of the other inputs, like edge detections. Likewise, we define the concept of **stride** as the number of inputs that feed into the same neuron and act as filters to each other.\n",
    "\n",
    "The idea of **filter size** also expand the layer of neuron from one array of neurons to a 2 dimensional array of neurons, with more and more arrays in parallel within that layer. Each filter is detecting a different feature.\n",
    "\n",
    "For simplicity, we describe and visualize these sets of neurons as blocks of 1 X L, and each block by a matrix of range (# of filters) x (# of neurons).\n",
    "\n",
    "For 2-D Convolution, we also consider the number of units W and the number of units H, so that the block turns into a 3 dimensional block with dimensions: (# of filters) x (# of neurons W) x (# of pixel height H). Subsections will be related to local sections of these blocks.\n",
    "\n",
    "Filters are commonly visualized with grids. Go to this [link](https://setosa.io/ev/image-kernels) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "We run into a possible issue for edge neurons! There may not be an input there for them. What we can do is *padding*, that is, add zeros around the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review Dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
