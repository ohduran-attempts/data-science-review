{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods\n",
    "\n",
    "Filter methods were those that select based on feature information. They should be the first step in any ML analysis.\n",
    "\n",
    "Basic filter methods consist of removing __constant__, __quasi constant__ or __duplicated__ features. Constant and quasi constant are features that always or almost always are the same value in each case, adding little to no value to the ML.\n",
    "\n",
    "One hot encoding may be a source of duplicated features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Features\n",
    "\n",
    "Constant features are those that show the same value, just one value, for all the observations of the dataset. This features provide no information that allows a ML model to discriminate or predict a target.\n",
    "\n",
    "Indentifying and removing constant features is an easy first step towards feature selection and more easily interpretable ML models.\n",
    "\n",
    "Here, we will demonstrate how to identify constant features using the Santander Customer Satisfaction dataset from Kaggle.\n",
    "\n",
    "To identify constant features, we can use the VarianceThreshold function from sklearn, or we can code it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Santander Customer Satisfaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the presence of NULL data. The snippets below will be able to compare NaN values between 2 columns, so in principle, missing data is not a problem. In any case, we see that there is no missing data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in data.columns if data[col].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Variance Threshold from sklearn\n",
    "[VarianceThreshold](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesn't meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(X_train) # fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [get_support](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold.get_support) to get the features that are retained after applying VarianceThreshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0', 'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46', 'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3', 'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3', 'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3', 'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3']\n"
     ]
    }
   ],
   "source": [
    "constant_features = [x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]\n",
    "\n",
    "print(constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the constant features, which means that 58 variables show the same value for all the observations of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[constant_features[0]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the transform function to reduce the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53214, 370) (22806, 370)\n",
      "(53214, 336) (22806, 336)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold from Scratch\n",
    "\n",
    "In the following, we will code the VarianceThreshold from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 370), (22806, 370))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_features_coded = [feat for feat in X_train.columns if X_train[feat].std() == 0]\n",
    "\n",
    "len(constant_features_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 332), (22806, 332))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(labels=constant_features_coded, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features_coded, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how by removing constant features, we managed to reduce the featured space quite a bit.\n",
    "\n",
    "Both VarianceThreshold and the snippet code work well with numerical variables.\n",
    "\n",
    "To do the same with categorical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold for Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 370), (22806, 370))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform into strings to be considered categories instead of values ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('O') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find constant features we need to find those that contain only 1 label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_features_categorical = [\n",
    "    feat for feat in X_train.columns if len(X_train[feat].unique()) == 1\n",
    "]\n",
    "\n",
    "len(constant_features_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can appreciate the usefulness of looking out for constant variables at the beginning of any modelling exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi Constant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quasi Constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little if any information that allows a machine learning model to discriminate or predict a target. But there can be exceptions, so you should be careful when removing these type of features.\n",
    "\n",
    "Identifying and removing quasi-constant features is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "To identify constante features, we use the VarianceThreshold function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 370), (22806, 370))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Constant Features\n",
    "First, we will remove the constant features from the dataset, which will allow for a better visualisation of the quasi-constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features are 38 out of 370\n",
      "After removing the constant features, the number of columns in the train set is 332\n"
     ]
    }
   ],
   "source": [
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "#X_train = X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "#X_test = X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "print('Constant features are {} out of {}'.format(len(constant_features), len(X_train.columns)))\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "print('After removing the constant features, the number of columns in the train set is {}'.format(len(X_train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Quasi-Constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(\n",
    "    threshold=0.1) # approximately indicates 99% of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features_not_quasi_constant = sum(sel.get_support())\n",
    "\n",
    "num_features_not_quasi_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "['ind_var1_0', 'ind_var1', 'ind_var5_0', 'ind_var6_0', 'ind_var6', 'ind_var8_0', 'ind_var8', 'ind_var12_0', 'ind_var12', 'ind_var13_0', 'ind_var13_corto_0', 'ind_var13_corto', 'ind_var13_largo_0', 'ind_var13_largo', 'ind_var13_medio_0', 'ind_var13_medio', 'ind_var13', 'ind_var14_0', 'ind_var14', 'ind_var17_0', 'ind_var17', 'ind_var18_0', 'ind_var18', 'ind_var19', 'ind_var20_0', 'ind_var20', 'ind_var24_0', 'ind_var24', 'ind_var25_cte', 'ind_var26_0', 'ind_var26_cte', 'ind_var26', 'ind_var25_0', 'ind_var25', 'ind_var29_0', 'ind_var29', 'ind_var30_0', 'ind_var31_0', 'ind_var31', 'ind_var32_cte', 'ind_var32_0', 'ind_var32', 'ind_var33_0', 'ind_var33', 'ind_var34_0', 'ind_var34', 'ind_var37_cte', 'ind_var37_0', 'ind_var37', 'ind_var40_0', 'ind_var40', 'ind_var39', 'ind_var44_0', 'ind_var44', 'num_var1_0', 'num_var1', 'num_var6_0', 'num_var6', 'num_var13_medio_0', 'num_var13_medio', 'num_var14', 'num_var17', 'num_var18_0', 'num_var18', 'num_var20_0', 'num_var20', 'num_op_var40_hace3', 'num_var29_0', 'num_var29', 'num_var32_0', 'num_var32', 'num_var33_0', 'num_var33', 'num_var34_0', 'num_var34', 'num_var40_0', 'num_var40', 'num_var39', 'num_var44_0', 'num_var44', 'delta_imp_aport_var33_1y3', 'delta_num_aport_var33_1y3', 'ind_var7_emit_ult1', 'ind_var7_recib_ult1', 'ind_var10_ult1', 'ind_var10cte_ult1', 'ind_var9_cte_ult1', 'ind_var9_ult1', 'ind_var43_emit_ult1', 'num_aport_var13_ult1', 'num_aport_var17_hace3', 'num_aport_var17_ult1', 'num_aport_var33_hace3', 'num_aport_var33_ult1', 'num_var7_emit_ult1', 'num_var7_recib_ult1', 'num_compra_var44_hace3', 'num_compra_var44_ult1', 'num_meses_var13_largo_ult3', 'num_meses_var13_medio_ult3', 'num_meses_var17_ult3', 'num_meses_var29_ult3', 'num_meses_var33_ult3', 'num_meses_var44_ult3', 'num_op_var40_efect_ult1', 'num_op_var40_efect_ult3', 'num_reemb_var13_ult1', 'num_reemb_var17_hace3', 'num_reemb_var17_ult1', 'num_sal_var16_ult1', 'num_trasp_var17_in_hace3', 'num_trasp_var17_in_ult1', 'num_trasp_var17_out_ult1', 'num_trasp_var33_in_hace3', 'num_trasp_var33_in_ult1', 'num_trasp_var33_out_ult1', 'num_venta_var44_hace3', 'num_venta_var44_ult1']\n"
     ]
    }
   ],
   "source": [
    "quasi_constant_features = [feat for feat in X_train.columns\n",
    "        if feat not in X_train.columns[sel.get_support()]]\n",
    "\n",
    "print(len(quasi_constant_features))\n",
    "print(quasi_constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take for instance the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.989044\n",
       "1    0.010956\n",
       "Name: ind_var1_0, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[quasi_constant_features[0]].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99% of observations show value 0. This feature can be described as quasi-constant. Let's remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Quasi-Constant features using bespoke code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 370), (22806, 370))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features are 38 out of 370\n",
      "After removing the constant features, the number of columns in the train set is 332\n"
     ]
    }
   ],
   "source": [
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "print('Constant features are {} out of {}'.format(len(constant_features), len(X_train.columns)))\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "print('After removing the constant features, the number of columns in the train set is {}'.format(len(X_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "quasi_constant_features = []\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    \n",
    "    # predominant value: the value that appears the most as a percentage of total value appearances\n",
    "    predominant_value = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "    \n",
    "    # evaluate predominant feature\n",
    "    if predominant_value > (1 - threshold * 0.2):\n",
    "        quasi_constant_features.append(feature)\n",
    "\n",
    "len(quasi_constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method was more aggresive than VarianceThreshold and thus the process was more restrictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imp_op_var40_comer_ult1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = quasi_constant_features[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00       0.996148\n",
       "396.00     0.000038\n",
       "714.09     0.000019\n",
       "103.80     0.000019\n",
       "450.00     0.000019\n",
       "247.56     0.000019\n",
       "683.43     0.000019\n",
       "2841.45    0.000019\n",
       "451.74     0.000019\n",
       "495.72     0.000019\n",
       "383.79     0.000019\n",
       "677.04     0.000019\n",
       "1987.47    0.000019\n",
       "2341.08    0.000019\n",
       "350.46     0.000019\n",
       "627.78     0.000019\n",
       "721.50     0.000019\n",
       "92.88      0.000019\n",
       "404.34     0.000019\n",
       "114.00     0.000019\n",
       "1482.30    0.000019\n",
       "2570.76    0.000019\n",
       "499.80     0.000019\n",
       "1030.77    0.000019\n",
       "327.00     0.000019\n",
       "713.91     0.000019\n",
       "563.97     0.000019\n",
       "4061.28    0.000019\n",
       "2822.58    0.000019\n",
       "3542.40    0.000019\n",
       "             ...   \n",
       "184.50     0.000019\n",
       "2105.43    0.000019\n",
       "140.55     0.000019\n",
       "572.91     0.000019\n",
       "867.87     0.000019\n",
       "368.94     0.000019\n",
       "299.82     0.000019\n",
       "1224.87    0.000019\n",
       "3639.87    0.000019\n",
       "1368.00    0.000019\n",
       "30.51      0.000019\n",
       "6300.69    0.000019\n",
       "373.50     0.000019\n",
       "541.29     0.000019\n",
       "408.51     0.000019\n",
       "834.96     0.000019\n",
       "195.18     0.000019\n",
       "194.82     0.000019\n",
       "137.94     0.000019\n",
       "1161.09    0.000019\n",
       "125.61     0.000019\n",
       "45.00      0.000019\n",
       "635.70     0.000019\n",
       "47.70      0.000019\n",
       "341.28     0.000019\n",
       "2012.76    0.000019\n",
       "1370.49    0.000019\n",
       "1436.19    0.000019\n",
       "17.25      0.000019\n",
       "84.00      0.000019\n",
       "Name: imp_op_var40_comer_ult1, Length: 205, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[sample].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature shows 0 for 99.6% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated Features\n",
    "\n",
    "Often, databases contain one or more features that show the same value across all the observations. This means that both features are in essence identical. It is not unusual to introduce duplicate features after performing __one hot__ encoding of categorical values, particularly when using several high cardinal variables.\n",
    "\n",
    "Identifying and removing duplicated, redundant features is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "There is no function in Python or Pandas to find duplicated columns. Therefore, we will use two code snippets to apply to small and large datasets.\n",
    "\n",
    "__Note__: Finding duplicated features is a computationally costly operation in Python, so you might not always want to perform it. Make sure you don't introduce duplicated values into the dataset, for starters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 370), (150, 370))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/santander.csv', nrows=500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a function 'duplicated' that evaluates if the dataframe contains duplicated rows. We can use this while transposing the dataset to look for columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>141</th>\n",
       "      <th>383</th>\n",
       "      <th>135</th>\n",
       "      <th>493</th>\n",
       "      <th>122</th>\n",
       "      <th>22</th>\n",
       "      <th>68</th>\n",
       "      <th>20</th>\n",
       "      <th>382</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>211</th>\n",
       "      <th>9</th>\n",
       "      <th>359</th>\n",
       "      <th>195</th>\n",
       "      <th>251</th>\n",
       "      <th>323</th>\n",
       "      <th>192</th>\n",
       "      <th>117</th>\n",
       "      <th>47</th>\n",
       "      <th>172</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>258.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>...</td>\n",
       "      <td>421.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>651.00</td>\n",
       "      <td>378.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var15</th>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1086.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>572.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           141    383    135    493    122   22     68    20   \\\n",
       "ID                       258.0  768.0  241.0  990.0  220.0  51.0  144.0  45.0   \n",
       "var3                       2.0    2.0    2.0    2.0    2.0   2.0    2.0   2.0   \n",
       "var15                     36.0   39.0   45.0   48.0   42.0  35.0   23.0  23.0   \n",
       "imp_ent_var16_ult1         0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "imp_op_var39_comer_ult1    0.0    0.0    0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "\n",
       "                           382      14   ...      211   9      359    195  \\\n",
       "ID                       767.0    32.00  ...    421.0  23.0  717.0  384.0   \n",
       "var3                       2.0     2.00  ...      2.0   2.0    2.0    2.0   \n",
       "var15                     41.0    33.00  ...     23.0  25.0   24.0   32.0   \n",
       "imp_ent_var16_ult1         0.0   600.00  ...      0.0   0.0    0.0    0.0   \n",
       "imp_op_var39_comer_ult1    0.0  1086.48  ...      0.0   0.0    0.0    0.0   \n",
       "\n",
       "                           251     323    192    117    47     172  \n",
       "ID                       501.0  651.00  378.0  213.0  107.0  332.0  \n",
       "var3                       2.0    2.00    2.0    2.0    2.0    2.0  \n",
       "var15                     24.0   37.00   27.0   55.0   42.0   38.0  \n",
       "imp_ent_var16_ult1         0.0    0.00    0.0    0.0    0.0    0.0  \n",
       "imp_op_var39_comer_ult1    0.0  572.19    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t = X_train.T\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are duplicated rows (the columns of the initial dataset) by applying .duplicated(), and then sum the number of rows being duplicates. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visually, the duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>141</th>\n",
       "      <th>383</th>\n",
       "      <th>135</th>\n",
       "      <th>493</th>\n",
       "      <th>122</th>\n",
       "      <th>22</th>\n",
       "      <th>68</th>\n",
       "      <th>20</th>\n",
       "      <th>382</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>211</th>\n",
       "      <th>9</th>\n",
       "      <th>359</th>\n",
       "      <th>195</th>\n",
       "      <th>251</th>\n",
       "      <th>323</th>\n",
       "      <th>192</th>\n",
       "      <th>117</th>\n",
       "      <th>47</th>\n",
       "      <th>172</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imp_op_var39_efect_ult1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_sal_var16_ult1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_var2_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_var2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_var6_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         141  383  135  493  122  22   68   20   382    14   \\\n",
       "imp_op_var39_efect_ult1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  360.0   \n",
       "imp_sal_var16_ult1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0   \n",
       "ind_var2_0               0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0   \n",
       "ind_var2                 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0   \n",
       "ind_var6_0               0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0   \n",
       "\n",
       "                        ...   211  9    359  195  251  323  192  117  47   172  \n",
       "imp_op_var39_efect_ult1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "imp_sal_var16_ult1      ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "ind_var2_0              ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "ind_var2                ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "ind_var6_0              ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t[data_t.duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imp_op_var39_efect_ult1', 'imp_sal_var16_ult1', 'ind_var2_0',\n",
       "       'ind_var2', 'ind_var6_0', 'ind_var6', 'ind_var13_largo',\n",
       "       'ind_var13_medio_0', 'ind_var13_medio', 'ind_var14', 'ind_var17',\n",
       "       'ind_var18_0', 'ind_var18', 'ind_var19', 'ind_var20', 'ind_var24',\n",
       "       'ind_var26_cte', 'ind_var26', 'ind_var25_0', 'ind_var25',\n",
       "       'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27',\n",
       "       'ind_var29_0', 'ind_var29', 'ind_var31', 'ind_var32_cte',\n",
       "       'ind_var32_0', 'ind_var32', 'ind_var33_0', 'ind_var33',\n",
       "       'ind_var34_0', 'ind_var34', 'ind_var37', 'ind_var40_0',\n",
       "       'ind_var40', 'ind_var41', 'ind_var39', 'ind_var44', 'ind_var46_0',\n",
       "       'ind_var46', 'num_var6_0', 'num_var6', 'num_var13_medio_0',\n",
       "       'num_var13_medio', 'num_var14', 'num_var17', 'num_var18_0',\n",
       "       'num_var18', 'num_var20', 'num_var24', 'num_var26', 'num_var25_0',\n",
       "       'num_var25', 'num_var27_0', 'num_var28_0', 'num_var28',\n",
       "       'num_var27', 'num_var29_0', 'num_var29', 'num_var31',\n",
       "       'num_var32_0', 'num_var32', 'num_var33_0', 'num_var33',\n",
       "       'num_var34_0', 'num_var34', 'num_var37', 'num_var40_0',\n",
       "       'num_var40', 'num_var41', 'num_var39', 'num_var44', 'num_var46_0',\n",
       "       'num_var46', 'saldo_var6', 'saldo_var13_medio', 'saldo_var14',\n",
       "       'saldo_var18', 'saldo_var20', 'saldo_var24', 'saldo_var25',\n",
       "       'saldo_var28', 'saldo_var27', 'saldo_var29', 'saldo_var32',\n",
       "       'saldo_var33', 'saldo_var34', 'saldo_var40', 'saldo_var41',\n",
       "       'saldo_var46', 'delta_imp_amort_var18_1y3',\n",
       "       'delta_imp_amort_var34_1y3', 'delta_imp_aport_var17_1y3',\n",
       "       'delta_imp_aport_var33_1y3', 'delta_imp_reemb_var13_1y3',\n",
       "       'delta_imp_reemb_var17_1y3', 'delta_imp_reemb_var33_1y3',\n",
       "       'delta_imp_trasp_var17_in_1y3', 'delta_imp_trasp_var17_out_1y3',\n",
       "       'delta_imp_trasp_var33_in_1y3', 'delta_imp_trasp_var33_out_1y3',\n",
       "       'delta_num_aport_var13_1y3', 'delta_num_aport_var17_1y3',\n",
       "       'delta_num_aport_var33_1y3', 'delta_num_compra_var44_1y3',\n",
       "       'delta_num_reemb_var13_1y3', 'delta_num_reemb_var17_1y3',\n",
       "       'delta_num_reemb_var33_1y3', 'delta_num_trasp_var17_in_1y3',\n",
       "       'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3',\n",
       "       'delta_num_trasp_var33_out_1y3', 'delta_num_venta_var44_1y3',\n",
       "       'imp_amort_var18_hace3', 'imp_amort_var18_ult1',\n",
       "       'imp_amort_var34_hace3', 'imp_amort_var34_ult1',\n",
       "       'imp_aport_var17_hace3', 'imp_aport_var17_ult1',\n",
       "       'imp_aport_var33_hace3', 'imp_aport_var33_ult1',\n",
       "       'imp_var7_emit_ult1', 'imp_reemb_var13_hace3',\n",
       "       'imp_reemb_var13_ult1', 'imp_reemb_var17_hace3',\n",
       "       'imp_reemb_var17_ult1', 'imp_reemb_var33_hace3',\n",
       "       'imp_reemb_var33_ult1', 'imp_trasp_var17_in_hace3',\n",
       "       'imp_trasp_var17_in_ult1', 'imp_trasp_var17_out_hace3',\n",
       "       'imp_trasp_var17_out_ult1', 'imp_trasp_var33_in_hace3',\n",
       "       'imp_trasp_var33_in_ult1', 'imp_trasp_var33_out_hace3',\n",
       "       'imp_trasp_var33_out_ult1', 'imp_venta_var44_hace3',\n",
       "       'ind_var7_emit_ult1', 'num_var2_0_ult1', 'num_var2_ult1',\n",
       "       'num_aport_var17_hace3', 'num_aport_var17_ult1',\n",
       "       'num_aport_var33_hace3', 'num_aport_var33_ult1',\n",
       "       'num_var7_emit_ult1', 'num_meses_var13_medio_ult3',\n",
       "       'num_meses_var29_ult3', 'num_meses_var33_ult3',\n",
       "       'num_op_var40_efect_ult1', 'num_op_var39_efect_ult1',\n",
       "       'num_reemb_var13_hace3', 'num_reemb_var13_ult1',\n",
       "       'num_reemb_var17_hace3', 'num_reemb_var17_ult1',\n",
       "       'num_reemb_var33_hace3', 'num_reemb_var33_ult1',\n",
       "       'num_sal_var16_ult1', 'num_trasp_var17_in_hace3',\n",
       "       'num_trasp_var17_in_ult1', 'num_trasp_var17_out_hace3',\n",
       "       'num_trasp_var17_out_ult1', 'num_trasp_var33_in_hace3',\n",
       "       'num_trasp_var33_in_ult1', 'num_trasp_var33_out_hace3',\n",
       "       'num_trasp_var33_out_ult1', 'num_venta_var44_hace3',\n",
       "       'num_venta_var44_ult1', 'saldo_var2_ult1',\n",
       "       'saldo_medio_var13_medio_hace2', 'saldo_medio_var13_medio_hace3',\n",
       "       'saldo_medio_var13_medio_ult1', 'saldo_medio_var13_medio_ult3',\n",
       "       'saldo_medio_var17_hace3', 'saldo_medio_var29_hace2',\n",
       "       'saldo_medio_var29_hace3', 'saldo_medio_var29_ult1',\n",
       "       'saldo_medio_var29_ult3', 'saldo_medio_var33_hace2',\n",
       "       'saldo_medio_var33_hace3', 'saldo_medio_var33_ult1',\n",
       "       'saldo_medio_var33_ult3'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_features = data_t[data_t.duplicated()].index.values\n",
    "duplicated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 187)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique = data_t.drop_duplicates(keep='first').T\n",
    "data_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now only 187 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing a dataframe is costly if the dataframe is big. Therefore, we can use the alternative loop to find duplicated columns in bigger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 370), (150, 370))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "duplicated_features = []\n",
    "\n",
    "for column in range(len(X_train.columns)):\n",
    "    if column % 10 == 0:\n",
    "        print(column)\n",
    "    \n",
    "    column_1 = X_train.columns[column]\n",
    "    \n",
    "    for column_2 in X_train.columns[column + 1:]:\n",
    "        if X_train[column_2].equals(X_train[column_1]):\n",
    "            duplicated_features.append(column_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "print(len(set(duplicated_features))) # use set to filter non uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 183 previously, so this makes sense, as we are using the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'delta_imp_aport_var17_1y3',\n",
       " 'delta_imp_aport_var33_1y3',\n",
       " 'delta_imp_reemb_var13_1y3',\n",
       " 'delta_imp_reemb_var17_1y3',\n",
       " 'delta_imp_reemb_var33_1y3',\n",
       " 'delta_imp_trasp_var17_in_1y3',\n",
       " 'delta_imp_trasp_var17_out_1y3',\n",
       " 'delta_imp_trasp_var33_in_1y3',\n",
       " 'delta_imp_trasp_var33_out_1y3',\n",
       " 'delta_num_aport_var13_1y3',\n",
       " 'delta_num_aport_var17_1y3',\n",
       " 'delta_num_aport_var33_1y3',\n",
       " 'delta_num_compra_var44_1y3',\n",
       " 'delta_num_reemb_var13_1y3',\n",
       " 'delta_num_reemb_var17_1y3',\n",
       " 'delta_num_reemb_var33_1y3',\n",
       " 'delta_num_trasp_var17_in_1y3',\n",
       " 'delta_num_trasp_var17_out_1y3',\n",
       " 'delta_num_trasp_var33_in_1y3',\n",
       " 'delta_num_trasp_var33_out_1y3',\n",
       " 'delta_num_venta_var44_1y3',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var18_ult1',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_amort_var34_ult1',\n",
       " 'imp_aport_var17_hace3',\n",
       " 'imp_aport_var17_ult1',\n",
       " 'imp_aport_var33_hace3',\n",
       " 'imp_aport_var33_ult1',\n",
       " 'imp_op_var39_efect_ult1',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var13_ult1',\n",
       " 'imp_reemb_var17_hace3',\n",
       " 'imp_reemb_var17_ult1',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_reemb_var33_ult1',\n",
       " 'imp_sal_var16_ult1',\n",
       " 'imp_trasp_var17_in_hace3',\n",
       " 'imp_trasp_var17_in_ult1',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var17_out_ult1',\n",
       " 'imp_trasp_var33_in_hace3',\n",
       " 'imp_trasp_var33_in_ult1',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'imp_trasp_var33_out_ult1',\n",
       " 'imp_var7_emit_ult1',\n",
       " 'imp_venta_var44_hace3',\n",
       " 'ind_var13_largo',\n",
       " 'ind_var13_medio',\n",
       " 'ind_var13_medio_0',\n",
       " 'ind_var14',\n",
       " 'ind_var17',\n",
       " 'ind_var18',\n",
       " 'ind_var18_0',\n",
       " 'ind_var19',\n",
       " 'ind_var2',\n",
       " 'ind_var20',\n",
       " 'ind_var24',\n",
       " 'ind_var25',\n",
       " 'ind_var25_0',\n",
       " 'ind_var26',\n",
       " 'ind_var26_cte',\n",
       " 'ind_var27',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28',\n",
       " 'ind_var28_0',\n",
       " 'ind_var29',\n",
       " 'ind_var29_0',\n",
       " 'ind_var2_0',\n",
       " 'ind_var31',\n",
       " 'ind_var32',\n",
       " 'ind_var32_0',\n",
       " 'ind_var32_cte',\n",
       " 'ind_var33',\n",
       " 'ind_var33_0',\n",
       " 'ind_var34',\n",
       " 'ind_var34_0',\n",
       " 'ind_var37',\n",
       " 'ind_var39',\n",
       " 'ind_var40',\n",
       " 'ind_var40_0',\n",
       " 'ind_var41',\n",
       " 'ind_var44',\n",
       " 'ind_var46',\n",
       " 'ind_var46_0',\n",
       " 'ind_var6',\n",
       " 'ind_var6_0',\n",
       " 'ind_var7_emit_ult1',\n",
       " 'num_aport_var17_hace3',\n",
       " 'num_aport_var17_ult1',\n",
       " 'num_aport_var33_hace3',\n",
       " 'num_aport_var33_ult1',\n",
       " 'num_meses_var13_medio_ult3',\n",
       " 'num_meses_var29_ult3',\n",
       " 'num_meses_var33_ult3',\n",
       " 'num_op_var39_efect_ult1',\n",
       " 'num_op_var40_efect_ult1',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var13_ult1',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_reemb_var33_ult1',\n",
       " 'num_sal_var16_ult1',\n",
       " 'num_trasp_var17_in_hace3',\n",
       " 'num_trasp_var17_in_ult1',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var17_out_ult1',\n",
       " 'num_trasp_var33_in_hace3',\n",
       " 'num_trasp_var33_in_ult1',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'num_trasp_var33_out_ult1',\n",
       " 'num_var13_medio',\n",
       " 'num_var13_medio_0',\n",
       " 'num_var14',\n",
       " 'num_var17',\n",
       " 'num_var18',\n",
       " 'num_var18_0',\n",
       " 'num_var20',\n",
       " 'num_var24',\n",
       " 'num_var25',\n",
       " 'num_var25_0',\n",
       " 'num_var26',\n",
       " 'num_var27',\n",
       " 'num_var27_0',\n",
       " 'num_var28',\n",
       " 'num_var28_0',\n",
       " 'num_var29',\n",
       " 'num_var29_0',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_var31',\n",
       " 'num_var32',\n",
       " 'num_var32_0',\n",
       " 'num_var33',\n",
       " 'num_var33_0',\n",
       " 'num_var34',\n",
       " 'num_var34_0',\n",
       " 'num_var37',\n",
       " 'num_var39',\n",
       " 'num_var40',\n",
       " 'num_var40_0',\n",
       " 'num_var41',\n",
       " 'num_var44',\n",
       " 'num_var46',\n",
       " 'num_var46_0',\n",
       " 'num_var6',\n",
       " 'num_var6_0',\n",
       " 'num_var7_emit_ult1',\n",
       " 'num_venta_var44_hace3',\n",
       " 'num_venta_var44_ult1',\n",
       " 'saldo_medio_var13_medio_hace2',\n",
       " 'saldo_medio_var13_medio_hace3',\n",
       " 'saldo_medio_var13_medio_ult1',\n",
       " 'saldo_medio_var13_medio_ult3',\n",
       " 'saldo_medio_var17_hace3',\n",
       " 'saldo_medio_var29_hace2',\n",
       " 'saldo_medio_var29_hace3',\n",
       " 'saldo_medio_var29_ult1',\n",
       " 'saldo_medio_var29_ult3',\n",
       " 'saldo_medio_var33_hace2',\n",
       " 'saldo_medio_var33_hace3',\n",
       " 'saldo_medio_var33_ult1',\n",
       " 'saldo_medio_var33_ult3',\n",
       " 'saldo_var13_medio',\n",
       " 'saldo_var18',\n",
       " 'saldo_var20',\n",
       " 'saldo_var24',\n",
       " 'saldo_var25',\n",
       " 'saldo_var27',\n",
       " 'saldo_var28',\n",
       " 'saldo_var29',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_var32',\n",
       " 'saldo_var33',\n",
       " 'saldo_var34',\n",
       " 'saldo_var40',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'saldo_var6'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(duplicated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
